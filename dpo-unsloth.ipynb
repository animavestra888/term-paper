{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -U -q transformers==4.51.3 datasets==3.5.0 bitsandbytes==0.45.5 triton==3.2.0 unsloth==2025.3.19 torch==2.6.0 peft==0.15.2 trl==0.15.2 wandb==0.19.10","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport wandb\nos.environ[\"WANDB_API_KEY\"] = \nos.environ[\"WANDB_PROJECT\"] = \"Coursework\" \nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import unsloth\nfrom unsloth import FastLanguageModel\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    DataCollatorForSeq2Seq\n)\nfrom peft import LoraConfig\nfrom transformers import BitsAndBytesConfig","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, \n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    \"Qwen/Qwen2.5-0.5B-Instruct\",\n    quantization_config=bnb_config,\n)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_alpha=16,\n    lora_dropout=0,\n    bias=\"none\",\n    use_gradient_checkpointing=True,\n    random_state=42,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")\neval_samples = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"test[:32]\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trl import DPOConfig\n\ndpo_args = DPOConfig(\n        output_dir=\"Qwen2.5-0.5B-Instruct-DPO\",\n        logging_steps=40,\n        max_length=1024,\n        fp16=True,\n        per_device_train_batch_size=1,\n        per_device_eval_batch_size=2,\n        gradient_accumulation_steps=4,\n        num_train_epochs=3,\n        eval_strategy='steps',\n        eval_steps=40,\n        optim='adamw_8bit',\n        learning_rate=5e-7,\n        lr_scheduler_type=\"cosine\",\n        warmup_ratio=0.05,  \n        beta=0.1,\n        gradient_checkpointing=True,\n        save_strategy=\"steps\",\n        save_steps=1000,\n        push_to_hub=True,\n        hub_model_id=\"theevolutionisnear/Qwen2.5-0.5B-Instruct-DPO\",\n        hub_strategy=\"checkpoint\",\n        hub_token=True,   \n        report_to=\"wandb\",\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# wandb.init(project=\"Coursework\",\n           # id=\"izl7baxm\",\n           # resume=\"must\")\n# artifact = run.use_artifact('animavestra888-independent/Coursework/model-qgdrqpv5:v7', type='model')\n# artifact_dir = artifact.download()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# _torch_load = torch.load\n\n# def _load_with_full_pickle(*args, **kwargs):\n#     \n#     kwargs[\"weights_only\"] = False\n\n#     return _torch_load(*args, **kwargs)\n# \n# torch.load = _load_with_full_pickle ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trl import DPOTrainer\n\ntrainer = DPOTrainer(\n    model=model,\n    ref_model=None,\n    args=dpo_args,\n    processing_class=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=eval_samples,\n)\n\ntrainer.train()\n#trainer.train(resume_from_checkpoint=artifact_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}