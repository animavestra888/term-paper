{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -U -q transformers==4.51.3 datasets==3.5.0 bitsandbytes==0.45.5 triton==3.2.0 unsloth==2025.3.19 torch==2.6.0 peft==0.15.2 trl==0.15.2 wandb==0.19.10","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport wandb\nos.environ[\"WANDB_API_KEY\"] = \nos.environ[\"WANDB_PROJECT\"] = \"Coursework\" \nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ndevice = torch.cuda.current_device()\ndevice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForImageTextToText\nfrom datasets import load_dataset\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n)\n\nmodel_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\npolicy_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map={\"\": device},\n    torch_dtype=torch.float16,\n)\n\npolicy_model = prepare_model_for_kbit_training(policy_model)\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_dropout=0,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\npolicy_model = get_peft_model(policy_model, lora_config)\npolicy_model.print_trainable_parameters()\n\nref_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map={\"\": device},\n    torch_dtype=torch.float16,\n)\n\nref_model.eval()\nfor param in ref_model.parameters():\n        param.requires_grad = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\ndef process_and_mask(examples, pairing_ratio=0.5, seed=42):\n    random.seed(seed)\n    instrs, resps, labels = [], [], []\n    for chosen_pair, rejected_pair in zip(examples['chosen'], examples['rejected']):\n        instruction = chosen_pair[0]['content']\n        chosen_resp = chosen_pair[1]['content']\n        rejected_resp = rejected_pair[1]['content']\n\n        if random.random() < pairing_ratio:\n            # оставляем один пример\n            if random.random() < 0.5:\n                instrs.append(instruction)\n                resps.append(chosen_resp)\n                labels.append(1.0)\n            else:\n                instrs.append(instruction)\n                resps.append(rejected_resp)\n                labels.append(-1.0)\n        else:\n            # оставляем оба\n            instrs.extend([instruction, instruction])\n            resps.extend([chosen_resp, rejected_resp])\n            labels.extend([1.0, -1.0])\n\n    return {'instruction': instrs, 'response': resps, 'label': labels}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" train_ds = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\").map(\n        process_and_mask, batched=True,\n        remove_columns=[\"chosen\",\"rejected\",\"score_chosen\",\"score_rejected\"]\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def expand_pair_batch(batch):\n    instrs, resps, labels = [], [], []\n    for chosen_pair, rejected_pair in zip(batch[\"chosen\"], batch[\"rejected\"]):\n        instruction   = chosen_pair[0][\"content\"]\n        chosen_resp   = chosen_pair[1][\"content\"]\n        rejected_resp = rejected_pair[1][\"content\"]\n\n        instrs.extend([instruction, instruction])\n        resps.extend([chosen_resp, rejected_resp])\n        labels.extend([1.0, -1.0])\n\n    return {\n        \"instruction\": instrs,\n        \"response\":    resps,\n        \"label\":       labels,\n    }\n\neval_raw = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"test[:32]\")\neval_ds  = eval_raw.map(\n    expand_pair_batch,\n    batched=True,\n    remove_columns=[\"chosen\",\"rejected\",\"score_chosen\",\"score_rejected\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bnf_loss(policy_logits, ref_logits, input_ids, pref_labels, pad_token_id):\n\n    policy_logps = policy_logits.log_softmax(-1)      # (B, T, V)\n    policy_ps    = policy_logps.exp()                 # (B, T, V)\n    ref_logps    = ref_logits.log_softmax(-1)         # (B, T, V)\n    ref_ps       = ref_logps.exp()                    # (B, T, V)\n\n    resp_ps      = policy_ps.gather(-1, input_ids.unsqueeze(-1)).squeeze(-1)      # (B, T)\n    resp_ps_ref  = ref_ps.gather(-1, input_ids.unsqueeze(-1)).squeeze(-1)         # (B, T)\n\n    resp_target = torch.clamp(resp_ps / resp_ps_ref, max=1.0).detach()             # (B, T)\n\n    denom = (1 - resp_ps).clamp(min=1e-8).unsqueeze(-1)                            # (B, T, 1)\n    others_target = ((1 - resp_target).unsqueeze(-1) / denom) * policy_ps.detach() # (B, T, V)\n\n    f_target = others_target.clone()\n    f_target.scatter_(-1, input_ids.unsqueeze(-1), resp_target.unsqueeze(-1))\n\n    ce = -(f_target * policy_logps).sum(-1)  # (B, T)\n\n    mask = (input_ids != pad_token_id).float()  # (B, T)\n    seq_loss = (ce * mask).sum(-1) / mask.sum(-1).clamp(min=1)  # (B,)\n\n    loss = (pref_labels * seq_loss).mean()\n\n    pref_mask = (pref_labels == 1)\n    dispref_mask = (pref_labels == -1)\n    with torch.no_grad():\n        pref_loss = seq_loss[pref_mask].mean() if pref_mask.any() else torch.tensor(0.)\n        dispref_loss = seq_loss[dispref_mask].mean() if dispref_mask.any() else torch.tensor(0.)\n    \n    return loss, pref_loss, dispref_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_fn(batch):\n    combined = [f\"Instruction: {x['instruction']}\\nResponse: {x['response']}\" for x in batch]\n    tokenized = tokenizer(\n        combined,\n        padding=\"longest\", \n        max_length=1024,\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n    return {\n        \"input_ids\": tokenized.input_ids,\n        \"attention_mask\": tokenized.attention_mask,\n        \"labels\": tokenized.input_ids.clone(),\n        \"preference_labels\": torch.tensor([x[\"label\"] for x in batch]).float()\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nimport numpy as np\n\nclass BNFTrainer(Trainer):\n    def __init__(self, *args, ref_model=None, pad_token_id=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ref_model = ref_model\n        self.pad_token_id = pad_token_id\n\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        with torch.no_grad():\n            ref_logits = self.ref_model(\n                input_ids=inputs[\"input_ids\"],\n                attention_mask=inputs[\"attention_mask\"]\n            ).logits\n        policy_logits = model(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"]\n        ).logits\n\n        loss, pref_loss, dispref_loss = bnf_loss(\n            policy_logits, ref_logits,\n            inputs[\"input_ids\"],\n            inputs[\"preference_labels\"],\n            self.pad_token_id\n        )\n\n        if self.state.global_step % self.args.logging_steps == 0:\n            self.log({\n                \"pref_loss\": float(pref_loss),\n                \"dispref_loss\": float(dispref_loss),\n                \"loss_ratio\": float(dispref_loss / (abs(pref_loss) + 1e-8))\n            })\n\n        return (loss, policy_logits) if return_outputs else loss\n\n    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix: str = \"eval\"):\n        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n        dataloader = self.get_eval_dataloader(eval_dataset)\n\n        sum_loss = 0.0\n        sum_pref_loss = 0.0\n        sum_dispref_loss = 0.0\n        count_loss = 0\n        count_pref = 0\n        count_dispref = 0\n\n        sum_diff_all = 0.0\n        count_tokens_all = 0\n        sum_diff_pref = 0.0\n        count_tokens_pref = 0\n        sum_diff_dispref = 0.0\n        count_tokens_dispref = 0\n\n        for batch in dataloader:\n            batch = self._prepare_inputs(batch)\n            with torch.no_grad():\n                ref_logits = self.ref_model(\n                    input_ids=batch[\"input_ids\"],\n                    attention_mask=batch[\"attention_mask\"]\n                ).logits\n                policy_logits = self.model(\n                    input_ids=batch[\"input_ids\"],\n                    attention_mask=batch[\"attention_mask\"]\n                ).logits\n\n                loss, pref_loss, dispref_loss = bnf_loss(\n                    policy_logits, ref_logits,\n                    batch[\"input_ids\"],\n                    batch[\"preference_labels\"],\n                    self.pad_token_id\n                )\n                \n                bs = batch[\"input_ids\"].size(0)\n                sum_loss += loss.item() * bs\n                count_loss += bs\n                if not torch.isnan(pref_loss):\n                    sum_pref_loss += pref_loss.item() * bs\n                    count_pref += bs\n                if not torch.isnan(dispref_loss):\n                    sum_dispref_loss += dispref_loss.item() * bs\n                    count_dispref += bs\n\n                logp_pol = torch.log_softmax(policy_logits, dim=-1)\n                logp_ref = torch.log_softmax(ref_logits, dim=-1)\n                mask = (batch[\"input_ids\"] != self.pad_token_id).float()\n                diff = (logp_pol.gather(-1, batch[\"input_ids\"].unsqueeze(-1)).squeeze(-1)\n                        - logp_ref.gather(-1, batch[\"input_ids\"].unsqueeze(-1)).squeeze(-1)) * mask\n                sum_diff_all += diff.sum().item()\n                count_tokens_all += mask.sum().item()\n\n                labels = batch[\"preference_labels\"]\n                pref_tok_mask = mask * (labels == 1).unsqueeze(-1).float()\n                dispref_tok_mask = mask * (labels == -1).unsqueeze(-1).float()\n                sum_diff_pref += (diff * pref_tok_mask.squeeze(-1)).sum().item()\n                count_tokens_pref += pref_tok_mask.sum().item()\n                sum_diff_dispref += (diff * dispref_tok_mask.squeeze(-1)).sum().item()\n                count_tokens_dispref += dispref_tok_mask.sum().item()\n\n\n        metrics = {}\n        metrics[f\"{metric_key_prefix}_loss\"] = sum_loss / count_loss\n        metrics[f\"{metric_key_prefix}_pref_loss\"] = sum_pref_loss / count_pref\n        metrics[f\"{metric_key_prefix}_dispref_loss\"] = sum_dispref_loss / count_dispref\n        metrics[f\"{metric_key_prefix}_ll_shift\"] = sum_diff_all / count_tokens_all\n        metrics[f\"{metric_key_prefix}_ll_shift_pref\"] = sum_diff_pref / count_tokens_pref\n        metrics[f\"{metric_key_prefix}_loss_ratio\"] = (sum_dispref_loss / count_dispref) / (sum_pref_loss / count_pref)\n\n        self.log({k: float(v) for k, v in metrics.items()})\n        return metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir='Qwen2.5-0.5B-Instruct-BNF',\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=4,\n    fp16=True,\n    eval_strategy='steps',\n    num_train_epochs=3,\n    logging_steps=40,\n    eval_steps=40,\n    optim='adamw_8bit',\n    learning_rate=5e-7,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.1,   \n    save_strategy='steps',\n    save_steps=1000,\n    push_to_hub=True,\n    hub_model_id='theevolutionisnear/Qwen2.5-0.5B-Instruct-BNF',\n    hub_strategy='checkpoint',\n    hub_token=True,\n    report_to='wandb',\n    remove_unused_columns=False,\n    gradient_checkpointing=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# wandb.init(project=\"Coursework\",\n#            id=\"crmnp6jy\",\n#            resume=\"must\")\n# artifact = run.use_artifact('animavestra888-independent/Coursework/model-crmnp6jy:v15', type='model')\n# artifact_dir = artifact.download()\n\n# _torch_load = torch.load\n\n# def _load_with_full_pickle(*args, **kwargs):\n#     kwargs[\"weights_only\"] = False\n\n#     return _torch_load(*args, **kwargs)\n\n# torch.load = _load_with_full_pickle ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = BNFTrainer(\n    model=policy_model,\n    ref_model=ref_model,\n    args=args,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    data_collator=collate_fn,\n    pad_token_id=tokenizer.pad_token_id,\n    )\ntrainer.train()\n#trainer.train(resume_from_checkpoint=artifact_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}